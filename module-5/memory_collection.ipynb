{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWhFuoX9cQZQik83spjA3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Digx1/langgraph-notes/blob/main/module-5/memory_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TVmM2_NNUfSk"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langchain_openai langgraph trustcall langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    # Check if the variable is set in the OS environment\n",
        "    env_value = os.environ.get(var)\n",
        "    if not env_value:\n",
        "        # If not set, prompt the user for input\n",
        "        env_value = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "    # Set the environment variable for the current process\n",
        "    os.environ[var] = env_value\n",
        "\n",
        "_set_env(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHsgEQHuVK3M",
        "outputId": "805828d6-8ef4-444f-a27f-44a075c50a43"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LANGCHAIN_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Memory(BaseModel):\n",
        "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
        "\n",
        "class MemoryCollection(BaseModel):\n",
        "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
      ],
      "metadata": {
        "id": "FObqGo8oVihs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_set_env(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO3O8q3YV2eg",
        "outputId": "6c1fc22f-70a5-4b49-d068-f566777c4afe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the model\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Bind schema to model\n",
        "model_with_structure = model.with_structured_output(MemoryCollection)\n",
        "\n",
        "# Invoke the model to produce structured output that matches the schema\n",
        "memory_collection = model_with_structure.invoke([HumanMessage(\"My name is digvijay. I like to bike.\")])\n",
        "memory_collection.memories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bibFcsmaWF4F",
        "outputId": "7027e65c-05be-4af3-dcf8-6f1a6730f4fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Memory(content=\"User's name is Digvijay.\"),\n",
              " Memory(content='User likes to bike.')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_collection.memories[1].model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXAlg22rW_8U",
        "outputId": "4df64508-c47e-4ad2-fae8-3ad30d12a15b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'content': 'User likes to bike.'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "# Initialize the in-memory store\n",
        "in_memory_store = InMemoryStore()\n",
        "\n",
        "# Namespace for the memory to save\n",
        "user_id = \"1\"\n",
        "namespace_for_memory = (user_id, \"memories\")\n",
        "\n",
        "# Save a memory to namespace as key and value\n",
        "key = str(uuid.uuid4())\n",
        "value = memory_collection.memories[0].model_dump()\n",
        "in_memory_store.put(namespace_for_memory, key, value)\n",
        "\n",
        "key = str(uuid.uuid4())\n",
        "value = memory_collection.memories[1].model_dump()\n",
        "in_memory_store.put(namespace_for_memory, key, value)"
      ],
      "metadata": {
        "id": "r11vQsOYXRb-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search\n",
        "for m in in_memory_store.search(namespace_for_memory):\n",
        "    print(m.dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pwpUNUQX6oZ",
        "outputId": "5fdce058-4aa7-4891-945c-544c97f633ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'namespace': ['1', 'memories'], 'key': '28bbf9a6-5683-416a-9907-69db8276308e', 'value': {'content': \"User's name is Digvijay.\"}, 'created_at': '2025-03-18T12:18:53.592045+00:00', 'updated_at': '2025-03-18T12:18:53.592050+00:00', 'score': None}\n",
            "{'namespace': ['1', 'memories'], 'key': '33a2aabe-1bd9-4265-952d-34bdb52815cd', 'value': {'content': 'User likes to bike.'}, 'created_at': '2025-03-18T12:18:53.592189+00:00', 'updated_at': '2025-03-18T12:18:53.592191+00:00', 'score': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trustcall import create_extractor\n",
        "\n",
        "# Create the extractor\n",
        "trustcall_extractor = create_extractor(\n",
        "    model,\n",
        "    tools=[Memory],\n",
        "    tool_choice=\"Memory\",\n",
        "    enable_inserts=True,\n",
        ")"
      ],
      "metadata": {
        "id": "tbOsnpZZNKU6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# Instruction\n",
        "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
        "\n",
        "# Conversation\n",
        "conversation = [HumanMessage(content=\"Hi, I'm digvijay.\"),\n",
        "                AIMessage(content=\"Nice to meet you, digvijay.\"),\n",
        "                HumanMessage(content=\"This morning I had a nice bike ride in San Francisco.\")]\n",
        "\n",
        "# Invoke the extractor\n",
        "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
      ],
      "metadata": {
        "id": "cihpJTkuNXs-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVK44DA8Nfuc",
        "outputId": "d26029d6-7ca3-4e39-bc5b-79e5985f449b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XzBwqEjXdRAmMhYU36MngXzD', 'function': {'arguments': '{\"content\":\"User, Digvijay, had a nice bike ride in San Francisco this morning.\"}', 'name': 'Memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 114, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_0d4eb8a50b', 'id': 'chatcmpl-BCQH6NFpJs4sNIWUSv7K2Hjbh6zHC', 'finish_reason': 'stop', 'logprobs': None}, id='run-38a59651-2c46-4e7b-80e8-fcc8b8bd5304-0', tool_calls=[{'name': 'Memory', 'args': {'content': 'User, Digvijay, had a nice bike ride in San Francisco this morning.'}, 'id': 'call_XzBwqEjXdRAmMhYU36MngXzD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 114, 'output_tokens': 23, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'responses': [Memory(content='User, Digvijay, had a nice bike ride in San Francisco this morning.')],\n",
              " 'response_metadata': [{'id': 'call_XzBwqEjXdRAmMhYU36MngXzD'}],\n",
              " 'attempts': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in result[\"messages\"]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvSDEjSsNmxz",
        "outputId": "87b26645-43b1-4881-f5d5-c35951db202e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Memory (call_2C31tAYUSe5SQe7u9Yupas2q)\n",
            " Call ID: call_2C31tAYUSe5SQe7u9Yupas2q\n",
            "  Args:\n",
            "    content: User, named Digvijay, had a nice bike ride in San Francisco this morning. After the ride, they went to Tartine and ate a croissant. They were also thinking about their trip to Japan and planning to go back this winter.\n",
            "  Memory (call_h83wZTNEO1kRWKvGWGBbtqDj)\n",
            " Call ID: call_h83wZTNEO1kRWKvGWGBbtqDj\n",
            "  Args:\n",
            "    content: User went to Tartine and ate a croissant after their bike ride in San Francisco. They were also thinking about their trip to Japan and planning to go back this winter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the conversation\n",
        "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"),\n",
        "                        HumanMessage(content=\"I went to Tartine and ate a croissant.\"),\n",
        "                        AIMessage(content=\"What else is on your mind?\"),\n",
        "                        HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),]\n",
        "\n",
        "# Update the instruction\n",
        "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
        "\n",
        "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
        "tool_name = \"Memory\"\n",
        "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
        "existing_memories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqnylFiWOZDm",
        "outputId": "ffcfb207-30d4-424c-affe-7acf023dd34a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0',\n",
              "  'Memory',\n",
              "  {'content': 'User, named Digvijay, had a nice bike ride in San Francisco this morning.'})]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the extractor with our updated conversation and existing memories\n",
        "result = trustcall_extractor.invoke({\"messages\": updated_conversation,\n",
        "                                     \"existing\": existing_memories})"
      ],
      "metadata": {
        "id": "p4Td7OFdOsAy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Responses contain the memories that adhere to the schema\n",
        "for m in result[\"responses\"]:\n",
        "    print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHYyKZtGO9kT",
        "outputId": "2ed25bf8-8ef5-4802-b600-96dd2ad68271"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='User, named Digvijay, had a nice bike ride in San Francisco this morning. After the ride, they went to Tartine and ate a croissant. They were also thinking about their trip to Japan and planning to go back this winter.'\n",
            "content='User went to Tartine and ate a croissant after their bike ride in San Francisco. They were also thinking about their trip to Japan and planning to go back this winter.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata contains the tool call\n",
        "for m in result[\"response_metadata\"]:\n",
        "    print(m)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIfryIf2PHgD",
        "outputId": "767a41e1-4d31-45f9-ce2d-d61fdcfb1eae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'call_2C31tAYUSe5SQe7u9Yupas2q', 'json_doc_id': '0'}\n",
            "{'id': 'call_h83wZTNEO1kRWKvGWGBbtqDj'}\n"
          ]
        }
      ]
    }
  ]
}